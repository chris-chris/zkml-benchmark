{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MLP Implementation with ezkl and Perceptron Layers\n",
        "\n",
        "In this notebook, we will implement a Multi-Layer Perceptron (MLP) with PyTorch and integrate it with ezkl for Zero-Knowledge Proofs. The depth of the MLP will be adjustable using the `expNum` parameter, and we will use a `perceptron` function to modularize the MLP layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import json\n",
        "import os\n",
        "import ezkl\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the Perceptron Function\n",
        "The perceptron function performs a linear transformation followed by a ReLU activation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define Perceptron function\n",
        "def perceptron(input_vector, weights, bias):\n",
        "    z = input_vector @ weights + bias\n",
        "    return torch.relu(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MLP Model Definition\n",
        "We define the MLP class using the perceptron function. The model's depth is adjustable via the `expNum` parameter, where `depth = 2^expNum`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the MLP model class\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size, output_size, depth):\n",
        "        super(MLP, self).__init__()\n",
        "        self.depth = depth\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # Initialize weights and biases for each layer\n",
        "        self.weights = [torch.randn(input_size, input_size) for _ in range(depth)]\n",
        "        self.biases = [torch.randn(input_size) for _ in range(depth)]\n",
        "        self.output_weight = torch.randn(input_size, output_size)\n",
        "        self.output_bias = torch.randn(output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i in range(self.depth):\n",
        "            x = perceptron(x, self.weights[i], self.biases[i])\n",
        "        output = x @ self.output_weight + self.output_bias\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Input Data from input.json\n",
        "We will now load input data from a JSON file named `input.json`, which contains 100 input vectors. Each input vector has 5 dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to load input data from JSON\n",
        "def load_input_data(json_file):\n",
        "    with open(json_file, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    return torch.tensor(data[\"input_data\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example `input.json` Structure\n",
        "Below is an example of how the `input.json` file should be structured:\n",
        "```json\n",
        "{\n",
        "    \"input_data\": [\n",
        "        [0.5, 0.2, -0.1, 0.8, 0.3],\n",
        "        [0.1, 0.4, 0.9, -0.5, 0.7],\n",
        "        [-0.3, 0.6, 0.2, 0.1, 0.8],\n",
        "        ...\n",
        "        [0.3, 0.2, -0.4, 0.5, 0.6]\n",
        "    ]\n",
        "}\n",
        "```\n",
        "Ensure that the file contains exactly 100 input vectors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run the MLP Model\n",
        "We will now run the MLP model with the loaded input data. The `expNum` variable determines the depth of the model, where `depth = 2^expNum`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the MLP model\n",
        "def run_mlp(exp_num):\n",
        "    input_size = 5\n",
        "    output_size = 1\n",
        "    depth = 2 ** exp_num  # Adjust model depth\n",
        "\n",
        "    model = MLP(input_size, output_size, depth)\n",
        "    \n",
        "    # Load input data from input.json\n",
        "    input_data = load_input_data('input.json')\n",
        "    \n",
        "    # Run the model\n",
        "    output = model(input_data)\n",
        "    print(\"Model Output:\", output)\n",
        "\n",
        "# Set expNum and run the model\n",
        "exp_num = 3  # Example depth setting (depth = 2^3 = 8)\n",
        "run_mlp(exp_num)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export the Model to ONNX Format\n",
        "Next, we will export the trained model to ONNX format so that it can be used with ezkl."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export the model to ONNX format\n",
        "onnx_path = 'mlp.onnx'\n",
        "input_data = load_input_data('input.json')\n",
        "\n",
        "torch.onnx.export(\n",
        "    model, \n",
        "    input_data, \n",
        "    onnx_path, \n",
        "    export_params=True, \n",
        "    opset_version=10, \n",
        "    input_names=['input'], \n",
        "    output_names=['output'], \n",
        "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
        ")\n",
        "print(f\"Model exported to {onnx_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using ezkl for Zero-Knowledge Proofs\n",
        "Finally, we integrate the model with ezkl to generate proofs and perform setup."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define paths for ezkl\n",
        "model_path = 'mlp.onnx'\n",
        "compiled_model_path = 'model.compiled'\n",
        "pk_path = 'pk.key'\n",
        "vk_path = 'test.vk'\n",
        "settings_path = 'settings.json'\n",
        "witness_path = 'witness.json'\n",
        "data_path = 'input.json'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate settings using ezkl\n",
        "res = ezkl.gen_settings(model_path, settings_path)\n",
        "assert res == True\n",
        "\n",
        "# Compile the model\n",
        "res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n",
        "assert res == True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate the witness file\n",
        "res = ezkl.gen_witness(data_path, compiled_model_path, witness_path)\n",
        "assert os.path.isfile(witness_path)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup the circuit with keys and parameters\n",
        "res = ezkl.setup(\n",
        "    compiled_model_path, \n",
        "    vk_path, \n",
        "    pk_path\n",
        ")\n",
        "\n",
        "assert res == True\n",
        "assert os.path.isfile(vk_path)\n",
        "assert os.path.isfile(pk_path)\n",
        "assert os.path.isfile(settings_path)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
